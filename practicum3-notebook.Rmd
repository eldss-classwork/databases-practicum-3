---
title: 'CS5200 Fall 2020: Practicum 3'
author: "Chandra Davis, Evan Douglass"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

## Overview

We've decided to work with SQLite for this practicum. As such, to work with these files you will need SQLite installed on your machine. The data we are using was provided with the practicum

```{r}
# Libraries needed for processing
library(RSQLite)
library("XML")
library(dplyr)
library(tibble)
```


## Part 1
Create a normalized relational OLTP database and populate it with data from an XML document.

### Task 1
Create a normalized relational schema that contains minimally the following entities: Article, Journal, Author, History. Use the XML document to determine the appropriate attributes (fields/columns) for the entities (tables). While there may be other types of publications in the XML, you only need to deal with articles in journals. Create appropriate primary and foreign keys. Where necessary, add surrogate keys. Include an image of an ERD showing your model in your R Notebook.

Lucidchart link: 

![Task1.1](imgs/OriginalTables.png)

### Task 2
Realize the relational schema in SQLite (place the CREATE TABLE statements into SQL chunks in your R Notebook).

```{r}
DB_NAME <- "pubMed.db"

conn <- dbConnect(RSQLite::SQLite(), DB_NAME)
```


```{r}
# Since the dataset is small, the database should be re-created at runtime
drop_table <- function(table_name) {
    paste("DROP TABLE IF EXISTS ", table_name, ";", sep="")
}

# Since we are dropping all tables, disable the FK checks
dbExecute(conn, "PRAGMA foreign_keys = OFF;")
# Get a list of all tables currently in the database
table_list <- dbListTables(conn)
# Drop every table in the database
for(table in table_list){
  dbExecute(conn, drop_table(table))
}
```

```{sql connection=conn}
PRAGMA foreign_keys = ON;
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS ELocType (
  eType_id INTEGER PRIMARY KEY AUTOINCREMENT,
  eType TEXT NOT NULL,
  CONSTRAINT unique_eLocType_eType UNIQUE (eType)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS CategoryLabels (
  label_id INTEGER PRIMARY KEY AUTOINCREMENT,
  label TEXT NOT NULL,
  CONSTRAINT unique_catLab_label UNIQUE (label)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Affiliations (
  aff_id INTEGER PRIMARY KEY AUTOINCREMENT,
  aff TEXT NOT NULL,
  CONSTRAINT unique_aff_aff UNIQUE (aff)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Pagination (
  pgn_id INTEGER PRIMARY KEY AUTOINCREMENT,
  medlinePgn TEXT NOT NULL,
  CONSTRAINT unique_pgn_medpgn UNIQUE (medlinePgn)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Languages (
  lang_id INTEGER PRIMARY KEY AUTOINCREMENT,
  language TEXT NOT NULL,
  CONSTRAINT unique_lang_lang UNIQUE (language)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS IsoAbbreviation (
  abbr_id INTEGER PRIMARY KEY AUTOINCREMENT,
  abbr TEXT NOT NULL,
  CONSTRAINT unique_isoAbbr_abbr UNIQUE (abbr)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS MediumType (
  medium_id INTEGER PRIMARY KEY AUTOINCREMENT,
  medium TEXT NOT NULL,
  CONSTRAINT unique_med_med UNIQUE (medium)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Countries (
  country_id INTEGER PRIMARY KEY AUTOINCREMENT,
  country TEXT NOT NULL,
  CONSTRAINT unique_country_country UNIQUE (country)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Agencies (
  agency_id INTEGER PRIMARY KEY AUTOINCREMENT,
  agency TEXT NOT NULL,
  CONSTRAINT unique_agency_agency UNIQUE (agency)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Acronyms (
  acronym_id INTEGER PRIMARY KEY AUTOINCREMENT,
  acronym TEXT NOT NULL,
  CONSTRAINT unique_acr_acr UNIQUE (acronym)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS PublicationType (
  pubType_id INTEGER PRIMARY KEY AUTOINCREMENT,
  pubType TEXT NOT NULL,
  CONSTRAINT unique_pubType_pubType UNIQUE (pubType)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS PubStatus (
  status_id INTEGER PRIMARY KEY AUTOINCREMENT,
  status TEXT NOT NULL,
  CONSTRAINT unique_pubStatus_status UNIQUE (status)
);
```


```{sql connection=conn}
CREATE TABLE IF NOT EXISTS Date (
  date_id INTEGER PRIMARY KEY AUTOINCREMENT,
  year INTEGER NOT NULL,
  month INTEGER NOT NULL,
  day INTEGER,
  CONSTRAINT unique_date_yymmdd UNIQUE (year, month, day)
);
```



### Task 3
Extract and transform the data from the XML and then load into the appropriate tables in the database. You cannot use xmlToDataFrame but instead must parse the XML node by node using a combination of node-by-node tree traversal and XPath. It is not feasible to use XPath to extract all journals, then all authors, etc. as some are missing and won't match up. You will need to iterate through the top-level nodes.

```{r}

```


## Part 2
Add to the normalized schema fact tables and turn the normalized schema into a de-normalized schema suitable for OLAP.

### Task 1
Create and populate a star schema with dimension and transaction fact tables. Each row in the fact table will represent one article. Include the image of an updated ERD that contains the fact table and any additional required dimension tables. Populate the star schema in R.

Lucidchart link: 

![Task2.1](imgs/OriginalTables.png)

```{r}

```


### Task 2
In the same schema as the previous step, create and populate a summary fact table that represents number of articles per time period (quarter, year) by author and by journal. Include the image of an updated ERD that contains the fact table. Populate the fact table in R.

Lucidchart link: 

![Task2.2](imgs/OriginalTables.png)

```{r}

```


## Part 3
Use the OLAP star schema to do some (simple) data mining.

### Task 1
Write queries using your data warehouse to explore whether the publications show a seasonal pattern. Look beyond the pattern of number of publications per season. Adjust your fact tables as needed to support your new queries. If you need to update the fact table, document your changes and your reasons why the changes are needed.

```{r}

```


### Task 2
Either (a) visualize (graph/plot) the data from the previous step using R to explore seasonality and explain what you found, or (b) build a predictive model to forecast the expected number of publications for a quarter. (Note that we do not cover predictive modeling in this course, so if you do not know this from a prior course, then simply create the visualization.)

```{r}

```


